name: Build & Upload Offline Installer Archives

on:
  workflow_call:
    inputs:
      ref:
        required: true
        type: string
      run_id:
        required: true
        type: string
      idf_version:
        required: false
        type: string
        description: "Specific IDF version to build (e.g., v5.1.2). If empty, builds all versions."
      debug:
        required: false
        type: boolean
        default: false
        description: "Debug mode: Uploads to debug folder, skips JSON update, skips purge."
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      DL_DISTRIBUTION_ID:
        required: true

  workflow_dispatch:
    inputs:
      run_id:
        description: "The run id from which to take binaries"
        required: true
        type: string
      idf_version:
        description: "Specific IDF version to build (e.g., v5.1.2). Leave empty to build all."
        required: false
        type: string
      purge_all:
        description: "Purge all existing archives from currently built IDF version from S3 before upload (DANGEROUS)"
        required: false
        type: boolean
        default: false
      debug:
        description: "Debug mode: Uploads to debug folder, skips JSON update, skips purge."
        required: false
        type: boolean
        default: false

concurrency:
  group: offline-installer-build
  cancel-in-progress: false

permissions:
  contents: read

jobs:
  get-versions:
    name: Get IDF Versions to Build
    runs-on: ubuntu-latest
    outputs:
      versions: ${{ steps.get-versions.outputs.versions }}
      should_purge: ${{ steps.get-versions.outputs.should_purge }}
      debug: ${{ steps.get-versions.outputs.debug }}
    steps:
      - name: Checkout (for scripts if needed)
        uses: actions/checkout@v4

      - name: Download offline_installer_builder artifact
        uses: actions/download-artifact@v5
        with:
          pattern: offline_installer_builder-linux-x64-*
          merge-multiple: true
          path: ./
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ inputs.run_id || github.run_id }}

      - name: Make binary executable
        run: chmod +x ./offline_installer_builder

      - name: Install UV
        uses: astral-sh/setup-uv@v2
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Get IDF versions
        id: get-versions
        run: |
          echo "debug=${{ inputs.debug }}" >> $GITHUB_OUTPUT

          if [ "${{ inputs.debug }}" = "true" ]; then
            echo "should_purge=false" >> $GITHUB_OUTPUT
          else
            SHOULD_PURGE=$([ "${{ github.event_name }}" = "release" ] || [ "${{ inputs.purge_all }}" = "true" ] && echo "true" || echo "false")
            echo "should_purge=$SHOULD_PURGE" >> $GITHUB_OUTPUT
          fi

          if [ -n "${{ inputs.idf_version }}" ]; then
            VERSIONS='["${{ inputs.idf_version }}"]'
          else
            echo "Getting available IDF versions..."
            VERSIONS_OUTPUT=$(./offline_installer_builder --list-versions)
            echo "Available versions:"
            echo "$VERSIONS_OUTPUT"
            VERSIONS=$(echo "$VERSIONS_OUTPUT" | jq -R -s -c 'split("\n") | map(select(length > 0))')
          fi

          echo "versions=$VERSIONS" >> $GITHUB_OUTPUT

  build-and-upload:
    name: Build & Upload (${{ matrix.package_name }}, ${{ matrix.idf_version }})
    needs: get-versions
    runs-on: ${{ matrix.os }}
    continue-on-error: false

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, ubuntu-24.04-arm, windows-latest, macos-latest, macos-15-intel]
        package_name: [linux-x64, linux-aarch64, windows-x64, macos-aarch64, macos-x64]
        idf_version: ${{ fromJson(needs.get-versions.outputs.versions) }}
        exclude:
          - os: ubuntu-latest
            package_name: linux-aarch64
          - os: ubuntu-latest
            package_name: windows-x64
          - os: ubuntu-latest
            package_name: macos-aarch64
          - os: ubuntu-latest
            package_name: macos-x64
          - os: ubuntu-24.04-arm
            package_name: linux-x64
          - os: ubuntu-24.04-arm
            package_name: windows-x64
          - os: ubuntu-24.04-arm
            package_name: macos-aarch64
          - os: ubuntu-24.04-arm
            package_name: macos-x64
          - os: windows-latest
            package_name: linux-x64
          - os: windows-latest
            package_name: linux-aarch64
          - os: windows-latest
            package_name: macos-aarch64
          - os: windows-latest
            package_name: macos-x64
          - os: macos-latest
            package_name: linux-x64
          - os: macos-latest
            package_name: linux-aarch64
          - os: macos-latest
            package_name: windows-x64
          - os: macos-latest
            package_name: macos-x64
          - os: macos-15-intel
            package_name: linux-x64
          - os: macos-15-intel
            package_name: linux-aarch64
          - os: macos-15-intel
            package_name: windows-x64
          - os: macos-15-intel
            package_name: macos-aarch64

    steps:
      - name: Checkout (for scripts if needed)
        uses: actions/checkout@v4

      - name: Download offline_installer_builder artifact
        uses: actions/download-artifact@v5
        with:
          pattern: offline_installer_builder-${{ matrix.package_name }}-*
          merge-multiple: true
          path: ./
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ inputs.run_id || github.run_id }}

      - name: Make binary executable (Unix)
        if: runner.os != 'Windows'
        run: chmod +x ./offline_installer_builder

        # Only needed for version IDF 5.1
      - name: Install dependencies (Unix)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libcairo2-dev \
            libpango1.0-dev \
            libjpeg-dev \
            libpng-dev \
            zlib1g-dev \
            meson \
            libglib2.0-dev \
            libssl-dev \
            libdbus-1-dev \
            libdbus-glib-1-dev \
            pkg-config

      - name: Install UV
        uses: astral-sh/setup-uv@v2

      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-east-1

      - name: Download current offline_archives.json
        if: needs.get-versions.outputs.should_purge == 'true'
        id: download_json
        shell: bash
        run: |
          aws s3 cp s3://espdldata/dl/eim/offline_archives.json ./offline_archives.json 2>/dev/null || echo "[]" > ./offline_archives.json
          if ! jq -e 'type == "array"' ./offline_archives.json >/dev/null 2>&1; then
            echo "[]" > ./offline_archives.json
          fi

      - name: Purge existing archives for this version (if requested) - Unix
        if: needs.get-versions.outputs.should_purge == 'true' && runner.os != 'Windows'
        shell: bash
        continue-on-error: true
        run: |
          echo "Purging existing archives for version ${{ matrix.idf_version }} from S3..."
          set +e
          aws s3 ls s3://espdldata/dl/eim/ | grep "archive_${{ matrix.idf_version }}_${{ matrix.package_name }}\.zst" | awk '{print $4}' | while read filename; do
            if [ -n "$filename" ]; then
              aws s3 rm "s3://espdldata/dl/eim/$filename" || true
            fi
          done
          exit 0

      - name: Purge existing archives for this version (if requested) - Windows
        if: needs.get-versions.outputs.should_purge == 'true' && runner.os == 'Windows'
        shell: pwsh
        continue-on-error: true
        run: |
          Write-Host "Purging existing archives for version ${{ matrix.idf_version }} from S3..."
          try {
            $archives = aws s3 ls s3://espdldata/dl/eim/ | Where-Object { $_.Split()[-1] -match "archive_${{ matrix.idf_version }}_${{ matrix.package_name }}\.zst" }
            if (-not $archives) { Write-Host "::warning::No existing archives found" }
            foreach ($archive in $archives) {
              $filename = $archive.Split()[-1]
              if ($filename) { aws s3 rm "s3://espdldata/dl/eim/$filename" || true }
            }
          } catch { Write-Host "::warning::Purge step encountered an error: $_" }
          exit 0

      - name: Build archive for specific version
        id: build
        shell: bash
        run: |
          if [ "${{ runner.os }}" = "Windows" ]; then
            BINARY="./offline_installer_builder.exe"
          else
            BINARY="./offline_installer_builder"
          fi
          echo "Building specific version: ${{ matrix.idf_version }}"
          PLATFORM="${{ matrix.package_name }}"
          VERSION="${{ matrix.idf_version }}"
          mkdir -p built_archives
          LOG_FILE="built_archives/archive_v${VERSION}_${PLATFORM}.log"

          set -o pipefail
          $BINARY -c default --idf-version-override ${{ matrix.idf_version }} 2>&1 | tee "$LOG_FILE"

          for file in archive_v*.zst; do
            if [ ! -f "$file" ]; then continue; fi
            NEW_NAME="archive_v${VERSION}_${PLATFORM}.zst"
            mv "$file" "built_archives/$NEW_NAME"
          done
          if [ ! "$(ls -A built_archives/*.zst 2>/dev/null)" ]; then
            echo "ERROR: No archives built!" >&2
            exit 1
          fi

      - name: Upload archive and log to S3 - Unix
        if: runner.os != 'Windows'
        id: upload_unix
        shell: bash
        env:
          S3_PREFIX: ${{ needs.get-versions.outputs.debug == 'true' && 'debug/' || '' }}
        run: |
          PLATFORM="${{ matrix.package_name }}"
          VERSION="${{ matrix.idf_version }}"
          archive=$(ls built_archives/*.zst | head -1)
          if [ ! -f "$archive" ]; then echo "ERROR: No archive found!" >&2; exit 1; fi

          FILENAME=$(basename "$archive")
          # Prepend prefix for JSON file logic
          JSON_FILENAME="${S3_PREFIX}${FILENAME}"

          if [ "${{ runner.os }}" = "macOS" ]; then
            SIZE=$(stat -f %z "$archive")
          else
            SIZE=$(stat -c %s "$archive")
          fi

          echo "Uploading to S3 prefix: ${S3_PREFIX}"

          # Upload Archive
          aws s3 cp --acl=public-read --content-type="application/zstd" "$archive" "s3://espdldata/dl/eim/${S3_PREFIX}${FILENAME}"

          # Upload Log
          LOG_FILE="${archive%.zst}.log"
          if [ -f "$LOG_FILE" ]; then
            LOG_FILENAME=$(basename "$LOG_FILE")
            aws s3 cp --acl=public-read --content-type="text/plain" "$LOG_FILE" "s3://espdldata/dl/eim/${S3_PREFIX}${LOG_FILENAME}"
          fi

          # Generate build-info.json with the correct path (including prefix)
          mkdir -p build-info
          jq -n \
            --arg version "$VERSION" \
            --arg platform "$PLATFORM" \
            --arg filename "$JSON_FILENAME" \
            --argjson size $SIZE \
            '{"version": $version, "platform": $platform, "filename": $filename, "size": $size}' \
            > "build-info/build-info.json"

      - name: Upload archive and log to S3 - Windows
        if: runner.os == 'Windows'
        id: upload_windows
        shell: pwsh
        env:
          S3_PREFIX: ${{ needs.get-versions.outputs.debug == 'true' && 'debug/' || '' }}
        run: |
          $PLATFORM = "${{ matrix.package_name }}"
          $VERSION = "${{ matrix.idf_version }}"
          $archive = Get-ChildItem "built_archives/*.zst" | Select-Object -First 1
          if (-not $archive) { Write-Error "ERROR: No archive found!"; exit 1 }

          $FILENAME = $archive.Name
          $archivePath = $archive.FullName
          $SIZE = $archive.Length
          $Prefix = "${{ env.S3_PREFIX }}"

          # Prepend prefix for JSON file logic
          $JsonFilename = "$Prefix$FILENAME"

          # Upload Archive
          aws s3 cp --acl=public-read --content-type="application/zstd" "$archivePath" "s3://espdldata/dl/eim/$Prefix$FILENAME"

          # Upload Log
          $LogFile = "$($archive.DirectoryName)\$($archive.BaseName).log"
          if (Test-Path $LogFile) {
             $LogFilename = Split-Path $LogFile -Leaf
             aws s3 cp --acl=public-read --content-type="text/plain" "$LogFile" "s3://espdldata/dl/eim/$Prefix$LogFilename"
          }

          # Generate build-info.json with the correct path
          New-Item -ItemType Directory -Path "build-info" -Force | Out-Null
          $buildInfo = @{
            version = $VERSION
            platform = $PLATFORM
            filename = $JsonFilename
            size = $SIZE
          }
          $buildInfo | ConvertTo-Json | Out-File -FilePath "build-info/build-info.json" -Encoding UTF8

      - name: Save build info as artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-info-${{ matrix.idf_version }}-${{ matrix.package_name }}
          path: build-info/
          retention-days: 7

  update-json:
    name: Update offline_archives.json
    needs: [get-versions, build-and-upload]
    if: needs.get-versions.outputs.debug != 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-east-1

      - name: Download current offline_archives.json
        run: |
          aws s3 cp s3://espdldata/dl/eim/offline_archives.json ./offline_archives.json 2>/dev/null || echo "[]" > ./offline_archives.json
          if ! jq -e 'type == "array"' ./offline_archives.json >/dev/null 2>&1; then
            echo "[]" > ./offline_archives.json
          fi

      - name: Purge old archives (if release)
        if: needs.get-versions.outputs.should_purge == 'true'
        run: |
          CUTOFF_TIME=$(date -d '24 hours ago' +%s)
          aws s3api list-objects-v2 \
            --bucket espdldata \
            --prefix dl/eim/archive_ \
            --query 'Contents[?ends_with(Key, `.zst`)].[Key,LastModified]' \
            --output text | while read -r key last_modified; do
            FILE_TIME=$(date -d "$last_modified" +%s)
            if [ $FILE_TIME -lt $CUTOFF_TIME ]; then
              aws s3 rm "s3://espdldata/$key"
              basename "$key" >> old_files.txt
            fi
          done
          touch old_files.txt

      - name: Download all build infos
        uses: actions/download-artifact@v4
        with:
          pattern: build-info-*
          path: ./all-build-infos/

      - name: Merge and update JSON
        run: |
          NEW_ENTRIES="[]"
          while IFS= read -r -d '' info_file; do
            if [ -f "$info_file" ] && jq empty "$info_file" 2>/dev/null; then
              entry=$(cat "$info_file")
              NEW_ENTRIES=$(echo "$NEW_ENTRIES" | jq --argjson entry "$entry" '. + [$entry]')
            fi
          done < <(find all-build-infos -name "build-info.json" -type f -print0)

          CURRENT=$(cat offline_archives.json)

          if [ -f old_files.txt ] && [ -s old_files.txt ]; then
            OLD_FILENAMES=$(jq -R -s -c 'split("\n") | map(select(length > 0))' old_files.txt)
            CURRENT=$(echo "$CURRENT" | jq --argjson old "$OLD_FILENAMES" 'map(select(.filename as $f | ($old | index($f)) | not))')
          fi

          UPDATED=$(echo "$CURRENT" | jq --argjson new "$NEW_ENTRIES" '
            . as $current |
            ($new | map({version, platform})) as $to_replace |
            ($current | map(select(
              (.version + "-" + .platform) as $key |
              ($to_replace | map(.version + "-" + .platform) | index($key)) | not
            ))) + $new
          ')

          echo "$UPDATED" > updated_offline_archives.json
          if ! jq empty updated_offline_archives.json; then echo "ERROR: JSON Invalid"; exit 1; fi

          aws s3 cp --acl=public-read updated_offline_archives.json s3://espdldata/dl/eim/offline_archives.json

          aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.DL_DISTRIBUTION_ID }} \
            --paths "/dl/eim/offline_archives.json" "/dl/eim/archive_*.zst"

  autotest:
    name: Autotest Offline Archives Installation
    needs: [build-and-upload]
    if: always() && needs.build-and-upload.result == 'success'
    uses: ./.github/workflows/test_offline.yml
    with:
      ref: ${{ inputs.ref || github.ref }}
      build_info_run_id: ${{ github.run_id }}
      eim_cli_run_id: ${{ inputs.run_id }}
